{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Epu1O72Qz_6G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "import json\n",
        "from PIL import Image\n",
        "import base64\n",
        "from mimetypes import guess_type\n",
        "import tiktoken\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWQUkQFcEG67"
      },
      "source": [
        "### Use local images\n",
        "#### to use local images, use the following code to convert it to base64 so it can be passed to the API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Read image from zip file and convert image to base64 format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UOri_nveFA7u"
      },
      "outputs": [],
      "source": [
        "# Function to encode a local image into a data URL\n",
        "def local_image_to_data_url(image_path):\n",
        "    mime_type, _ = guess_type(image_path)\n",
        "    if mime_type is None:\n",
        "        mime_type = 'application/octet-stream'\n",
        "\n",
        "    # Read and encode the image file\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "    return f\"data:{mime_type};base64,{base64_encoded_data}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to read images from a zip file\n",
        "def read_images_from_zip(zip_file_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "        return [os.path.join(extract_to, file_name) for file_name in zip_ref.namelist()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to convert images from a zip file to data URLs and save to a JSON file\n",
        "def convert_images_from_zip_to_data_urls(zip_file_path, output_json_path):\n",
        "    # Read image paths from the zip file\n",
        "    image_paths = read_images_from_zip(zip_file_path, './')\n",
        "    \n",
        "    data_urls = {}\n",
        "    for image_path in image_paths:\n",
        "        image_name = os.path.basename(image_path)\n",
        "        data_url = local_image_to_data_url(image_path)\n",
        "        data_urls[image_name] = data_url\n",
        "\n",
        "    # Save the data URLs to a JSON file\n",
        "    with open(output_json_path, 'w') as json_file:\n",
        "        json.dump(data_urls, json_file, indent=4)\n",
        "\n",
        "    return data_urls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "zip_file_path = \"./images_full.zip\"\n",
        "output_path =  \"./image_urls_full.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_data = convert_images_from_zip_to_data_urls(zip_file_path, output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3NBc4tnEffV"
      },
      "source": [
        "### GPT-4 with Vision for VQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[9642, 2822]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoding = tiktoken.encoding_for_model(\"gpt-4-vision-preview\")\n",
        "\n",
        "encoding.encode(\"YesNo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d3MmZKr00Lv6"
      },
      "outputs": [],
      "source": [
        "client = OpenAI()\n",
        "\n",
        "def openai_vqa(\n",
        "    question,\n",
        "    image_url,\n",
        "    # model=\"gpt-4-vision-preview\",\n",
        "    model='gpt-4o',\n",
        "    top_p=0.1,\n",
        "    logit_bias={9642:100, 2822:100},  # tokens for Yes (9642), No (2822)\n",
        "    max_tokens=1,\n",
        "    return_response=False\n",
        "):\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\",\n",
        "                     \"text\": f\"You are a helpful assistant. Please answer the question only with 'Yes' or 'No'. Do not give other outputs. Question: {question}\"},\n",
        "                    {\"type\": \"image_url\",\n",
        "                     \"image_url\": {\n",
        "                           \"url\": image_url,\n",
        "                           'detail': 'low'\n",
        "                           },}\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        top_p=top_p,\n",
        "        logit_bias=logit_bias,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "\n",
        "    if return_response:\n",
        "        return resp\n",
        "\n",
        "    return resp.choices[0].message.content[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the partially processed data\n",
        "def load_data(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, 'r') as file:\n",
        "            return json.load(file)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Check if an image has already been processed\n",
        "def is_processed(image_data):\n",
        "    return 'qid2answer' in image_data and 'qid2scores' in image_data\n",
        "\n",
        "file_path = 'evaluated_data_gpt4o.json'\n",
        "\n",
        "partial_data = load_data(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize storage for answers and scores\n",
        "for image_data in partial_data:\n",
        "    if is_processed(image_data):\n",
        "        continue  # Skip already processed images\n",
        "\n",
        "    qid2answer = {}\n",
        "    qid2scores = {}\n",
        "    \n",
        "    image_id = image_data['image_id']\n",
        "    image_url = image_data['image_url']\n",
        "    qid2question = image_data['qid2question']\n",
        "    qid2dependency = image_data['qid2dependency']\n",
        "\n",
        "    for id, question in qid2question.items():\n",
        "        try:\n",
        "            answer = openai_vqa(question, image_url)\n",
        "            qid2answer[id] = answer\n",
        "            qid2scores[id] = float(answer == 'Y')\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing question {id}: {e}\")\n",
        "            qid2answer[id] = None\n",
        "            qid2scores[id] = 0.0\n",
        "\n",
        "    # Store results back into the JSON structure\n",
        "    image_data['qid2answer'] = qid2answer\n",
        "    image_data['qid2scores'] = qid2scores\n",
        "\n",
        "    # Periodically save the updated JSON data to a file\n",
        "    try:\n",
        "        with open(file_path, 'w') as file:\n",
        "            json.dump(partial_data, file, indent=4)\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving data: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qWQUkQFcEG67"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
